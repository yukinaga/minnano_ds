{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/minnano_ds/blob/main/section_5/01_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsdhCm7yB71r"
      },
      "source": [
        "#  回帰\n",
        "回帰は、教師あり学習の一種で、変数間の関係を予測します。  \n",
        "今回は、単回帰と重回帰の２つを解説します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgby3w-wB_6w"
      },
      "source": [
        "## ●データセットの読み込み\n",
        "ボストン住宅価格のデータセットを読み込みます。  \n",
        "このデータセットには、**説明変数**と**目的変数**が含まれます。  \n",
        "**説明変数**: 何かの原因となっている変数  \n",
        "**目的変数**: その原因を受けて発生した結果である変数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlCabWPRDYLd"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "\n",
        "boston = datasets.load_boston()\n",
        "boston_df = pd.DataFrame(boston.data, columns=boston.feature_names)  # data: 説明変数\n",
        "boston_df[\"PRICE\"] = boston.target  # target: 目的変数\n",
        "boston_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg-bGiq0liRo"
      },
      "source": [
        "説明変数が様々な住宅の特徴で、目的変数が住宅の価格であることが分かります。  \n",
        "各列のラベルの意味は、`DESCR`により表示することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Qgk5prfZno"
      },
      "source": [
        "print(boston.DESCR)  # データセットの説明"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrhhxgg3mdF3"
      },
      "source": [
        "データセットの特徴を把握するために、統計量を表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGl9eXt-RVnu"
      },
      "source": [
        "boston_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NrEwdREmpOQ"
      },
      "source": [
        "データセットを、訓練用のデータとテスト用のデータに分割します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gr3rX3uYxGr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 訓練データとテストデータに分割\n",
        "x_train, x_test, t_train, t_test = train_test_split(boston.data, boston.target, random_state=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P87IMlUQtsN"
      },
      "source": [
        "## ●単回帰\n",
        "単回帰では、直線を使い1つの説明変数で目的変数を予測します。  \n",
        "$x$を説明変数、$y$を目的変数、$a$を係数、$b$を切片としたとき、単回帰は以下の式で表されます。  \n",
        "$$y = ax + b$$\n",
        "\n",
        "以下のコードでは、linear_model.LinearRegressionにより線形回帰のモデルを生成し、fitメソッドにより、モデルの訓練を行います。  \n",
        "説明変数にRM（部屋数）のみを使うことで単回帰になります。    \n",
        "訓練の結果、式の係数と切片が最適化されます。  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgnQ5FJCQstZ"
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "# RM（部屋数）の列を取得\n",
        "x_rm_train = x_train[:, [5]]\n",
        "x_rm_test = x_test[:, [5]]\n",
        "\n",
        "model = linear_model.LinearRegression() # 線形回帰モデル\n",
        "model.fit(x_rm_train, t_train)  # モデルの訓練"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBgb0ZLJt7rz"
      },
      "source": [
        "訓練済みのモデルから、式の係数と切片を取得します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRNtXC_mTDy6"
      },
      "source": [
        "a = model.coef_ # 係数\n",
        "b = model.intercept_ # 切片\n",
        "print(\"a: \", a) \n",
        "print(\"b: \", b) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgtKKpm3xMqG"
      },
      "source": [
        "取得した係数と切片を使った回帰直線を、元のデータとともにグラフで表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pj4AMghTEqb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(x_rm_train, t_train, label=\"Train\")\n",
        "plt.scatter(x_rm_test, t_test, label=\"Test\")\n",
        "\n",
        "y_reg = a * x_rm_train + b  # 回帰直線\n",
        "plt.plot(x_rm_train, y_reg, c=\"red\") \n",
        "\n",
        "plt.xlabel(\"Rooms\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfmsL445zs7a"
      },
      "source": [
        "上記の結果は、回帰直線は、部屋数が多くなると価格が上がるというデータの傾向をシンプルに表しています。  \n",
        "  \n",
        "次に、モデルのMSE（平均二乗誤差 Mean Squared Error）を計算します。  \n",
        "\n",
        "MSEは、$E$を誤差、$y_k$を予測値、$t_k$を正解値として以下の式で定義されます。\n",
        "\n",
        "$$ E = \\frac{1}{n} \\sum_{k=1}^n(y_k-t_k)^2 $$\n",
        "\n",
        "この誤差が小さいほどモデルの誤差が小さくなります。  \n",
        "\n",
        "以下のコードは、訓練データとテストデータ、それぞれで`mean_squared_error`によりMSEを計算します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEyltLb0TNYW"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 訓練データ\n",
        "y_train = model.predict(x_rm_train)\n",
        "mse_train = mean_squared_error(t_train, y_train)\n",
        "print(\"MSE(Train): \", mse_train)\n",
        "\n",
        "# テストデータ\n",
        "y_test = model.predict(x_rm_test)\n",
        "mse_test = mean_squared_error(t_test, y_test)\n",
        "print(\"MSE(Test): \", mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dScbFa4HU5Zj"
      },
      "source": [
        "## ●重回帰\n",
        "重回帰では、複数の説明変数を使い目的変数を予測します。  \n",
        "重回帰は、$x_k$を各説明変数として以下の式で表されます。\n",
        "\n",
        "$$ y = \\sum_{k=1}^na_kx_k + b $$\n",
        "\n",
        "今回は、13種類の説明変数を全て使って重回帰分析を行います。  \n",
        "単回帰の場合と同じく、linear_model.LinearRegressionを使います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Sr3TJuU4jT"
      },
      "source": [
        "model = linear_model.LinearRegression() # 線形回帰\n",
        "\n",
        "# 全ての説明変数を使い学習\n",
        "model.fit(x_train, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HItdTbCX7Nsd"
      },
      "source": [
        "各説明変数に対応した係数を取得します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg1l1t7mV8ma"
      },
      "source": [
        "a_df = pd.DataFrame(boston.feature_names, columns=[\"Exp\"])\n",
        "a_df[\"a\"] = pd.Series(model.coef_)\n",
        "a_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27-HM_yb8ekG"
      },
      "source": [
        "切片を取得します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl9WSsgwWMFD"
      },
      "source": [
        "print(\"b: \", model.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ANkxMZz8tpr"
      },
      "source": [
        "訓練データとテストデータ、それぞれでMSE（平均二乗誤差）を計算します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSAEnKfTWPn1"
      },
      "source": [
        "# 訓練データ\n",
        "y_train = model.predict(x_train)\n",
        "mse_train = mean_squared_error(t_train, y_train)\n",
        "print(\"MSE(Train): \", mse_train)\n",
        "\n",
        "# テストデータ\n",
        "y_test = model.predict(x_test)\n",
        "mse_test = mean_squared_error(t_test, y_test)\n",
        "print(\"MSE(Test): \", mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSDZ-RKt9g2D"
      },
      "source": [
        "単回帰の場合よりも誤差が小さくなりました。  \n",
        "ただ、テストデータの誤差は訓練データの誤差よりも大幅に大きくなりました。  \n",
        "モデルが訓練データに過剰に適合していないか、慎重に判断する必要があります。"
      ]
    }
  ]
}